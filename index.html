<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />
    <title>Local Language Speech to Text</title>
    <link rel="manifest" href="manifest.json" />
    <meta name="theme-color" content="#2c3e50" />
    <style>
      :root {
        --primary-color: #9c27b0;
        --secondary-color: #3498db;
        --warning-color: #f39c12;
        --success-color: #4caf50;
        --danger-color: #e74c3c;
        --dark-color: #2c3e50;
        --light-color: #ecf0f1;
      }

      * {
        box-sizing: border-box;
        -webkit-tap-highlight-color: transparent;
      }

      body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
          Helvetica, Arial, sans-serif;
        line-height: 1.6;
        margin: 0;
        padding: 0;
        background-color: #f5f7fa;
        color: #333;
        touch-action: manipulation;
      }

      .container {
        max-width: 100%;
        margin: 0;
        background: white;
        padding: 15px;
        min-height: 100vh;
      }

      h1 {
        text-align: center;
        color: var(--dark-color);
        margin-bottom: 20px;
        font-size: 1.5rem;
      }

      .control-panel {
        display: flex;
        flex-wrap: wrap;
        gap: 8px;
        margin-bottom: 15px;
        justify-content: center;
      }

      button {
        padding: 12px 16px;
        border: none;
        border-radius: 8px;
        cursor: pointer;
        font-weight: bold;
        transition: all 0.2s;
        font-size: 0.9rem;
        flex: 1 1 120px;
        min-width: 0;
        max-width: 200px;
        touch-action: manipulation;
      }

      button:active {
        transform: scale(0.98);
      }

      #toggleBtn {
        background-color: var(--primary-color);
        color: white;
      }

      #addNoteBtn {
        background-color: var(--secondary-color);
        color: white;
      }

      #clearBtn {
        background-color: var(--warning-color);
        color: white;
      }

      #translateBtn {
        background-color: var(--success-color);
        color: white;
      }

      #exportBtn {
        background-color: #2196f3;
        color: white;
      }

      #importBtn {
        background-color: #607d8b;
        color: white;
      }

      button:hover {
        opacity: 0.9;
      }

      button:disabled {
        opacity: 0.6;
        cursor: not-allowed;
        transform: none !important;
      }

      .status {
        text-align: center;
        margin: 12px 0;
        padding: 10px;
        border-radius: 8px;
        background-color: var(--light-color);
        font-size: 0.9rem;
      }

      .transcript-container {
        display: flex;
        flex-direction: column;
        gap: 15px;
        margin-top: 15px;
      }

      .text-display,
      .notes-display {
        width: 100%;
        min-height: 150px;
        padding: 12px;
        border-radius: 8px;
        background-color: #f9f9f9;
        border: 1px solid #ddd;
        font-size: 1rem;
        overflow-y: auto;
        -webkit-overflow-scrolling: touch;
      }

      .text-display {
        font-size: 1rem;
      }

      .notes-display {
        background-color: #fffde7;
      }

      .notes-list {
        list-style-type: none;
        padding: 0;
        margin: 0;
      }

      .note-item {
        padding: 12px;
        margin-bottom: 10px;
        background-color: #fff9c4;
        border-left: 4px solid #ffd600;
        border-radius: 6px;
        position: relative;
        word-break: break-word;
      }

      .note-item .delete-note {
        position: absolute;
        right: 8px;
        top: 8px;
        background: var(--danger-color);
        color: white;
        border: none;
        border-radius: 50%;
        width: 24px;
        height: 24px;
        font-size: 14px;
        line-height: 24px;
        text-align: center;
        cursor: pointer;
        padding: 0;
      }

      .settings {
        margin-top: 15px;
        padding: 12px;
        background-color: var(--light-color);
        border-radius: 8px;
        font-size: 0.9rem;
      }

      .translation-panel {
        margin-top: 15px;
        padding: 12px;
        background-color: #e3f2fd;
        border-radius: 8px;
      }

      .translation-result {
        margin-top: 10px;
        padding: 10px;
        background-color: #e8f5e9;
        border-radius: 8px;
        min-height: 60px;
        word-break: break-word;
      }

      select {
        padding: 10px;
        border-radius: 8px;
        border: 1px solid #bdc3c7;
        width: 100%;
        margin-top: 8px;
        font-size: 0.9rem;
        background-color: white;
      }

      label {
        display: block;
        margin-bottom: 5px;
        font-weight: bold;
      }

      #targetLanguage {
        margin-top: 10px;
        margin-left: 0;
      }

      footer {
        text-align: center;
        margin-top: 20px;
        color: #7f8c8d;
        font-size: 0.8rem;
        padding: 10px;
      }

      .listening-indicator {
        display: inline-block;
        width: 12px;
        height: 12px;
        border-radius: 50%;
        background-color: var(--success-color);
        margin-right: 8px;
        animation: pulse 1.5s infinite;
      }

      @keyframes pulse {
        0% {
          transform: scale(1);
        }
        50% {
          transform: scale(1.2);
        }
        100% {
          transform: scale(1);
        }
      }

      /* Offline indicator */
      .offline-status {
        position: fixed;
        bottom: 10px;
        left: 10px;
        padding: 5px 10px;
        background-color: var(--warning-color);
        color: white;
        border-radius: 3px;
        font-size: 12px;
        z-index: 1000;
      }

      .audio-controls {
        margin-top: 15px;
        padding: 12px;
        background-color: #f5f5f5;
        border-radius: 8px;
      }

      .audio-panel {
        display: flex;
        flex-wrap: wrap;
        gap: 10px;
        margin-bottom: 10px;
      }

      #audioVisualizer {
        border-radius: 8px;
        overflow: hidden;
        width: 100%;
        height: 80px;
        background-color: #f0f0f0;
        margin-top: 10px;
      }

      /* RTL support for right-to-left languages */
      .rtl-text {
        direction: rtl;
        text-align: right;
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
      }

      /* Confidence indicator */
      .confidence-indicator {
        height: 4px;
        background-color: #e0e0e0;
        margin-top: 5px;
        border-radius: 2px;
        overflow: hidden;
      }

      .confidence-level {
        height: 100%;
        background-color: var(--success-color);
        width: 0%;
        transition: width 0.3s ease;
      }

      /* Android-specific optimizations */
      .android-warning {
        background-color: #fff3e0;
        padding: 10px;
        border-radius: 8px;
        margin-bottom: 15px;
        font-size: 0.9rem;
        border-left: 4px solid #ffa000;
      }

      /* Export dialog styles */
      .export-dialog {
        position: fixed;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        background-color: white;
        padding: 20px;
        border-radius: 8px;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.2);
        z-index: 1000;
        width: 90%;
        max-width: 400px;
      }

      .export-dialog h3 {
        margin-top: 0;
        margin-bottom: 15px;
      }

      .export-dialog button {
        display: block;
        width: 100%;
        margin-bottom: 10px;
        padding: 12px;
      }

      .export-dialog button:last-child {
        margin-bottom: 0;
        background-color: #f5f5f5;
        color: #333;
      }

      /* Mobile-specific optimizations */
      @media (min-width: 768px) {
        .container {
          max-width: 900px;
          margin: 0 auto;
          padding: 25px;
          min-height: auto;
        }

        .transcript-container {
          flex-direction: row;
        }

        .text-display,
        .notes-display {
          min-height: 250px;
        }

        select {
          width: auto;
          margin-top: 0;
        }

        #targetLanguage {
          margin-left: 10px;
          margin-top: 0;
        }

        button {
          flex: 0 1 auto;
        }
      }

      /* Very small devices */
      @media (max-width: 360px) {
        button {
          padding: 10px 12px;
          font-size: 0.8rem;
        }
      }

      /* Prevent zoom on input focus */
      @media screen and (-webkit-min-device-pixel-ratio: 0) {
        select,
        textarea,
        input {
          font-size: 16px;
        }
      }

      /* Swipe to delete for notes */
      .note-item {
        transition: transform 0.2s;
      }

      .note-item.swiping {
        transition: none;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>Local Language Speech to Text</h1>

      <div class="android-warning" id="androidWarning">
        <strong>Note for Android Users:</strong> For best results with local
        languages, use Chrome browser and ensure you have the language pack
        installed for your device.
      </div>

      <div class="status" id="status">
        <span class="listening-indicator"></span>Auto-listening activated...
      </div>

      <div class="control-panel">
        <button id="toggleBtn">Pause Listening</button>
        <button id="addNoteBtn">Add as Note</button>
        <button id="clearBtn">Clear All</button>
        <button id="exportBtn">Export Notes</button>
        <button id="importBtn">Import Notes</button>
      </div>

      <div class="transcript-container">
        <div class="text-display" id="textDisplay" contenteditable="true">
          Your transcribed text will appear here...
        </div>

        <div class="notes-display">
          <h3>Your Notes</h3>
          <ul class="notes-list" id="notesList"></ul>
        </div>
      </div>

      <div class="settings">
        <label for="languageSelect">Speech Language:</label>
        <select id="languageSelect">
          <!-- Enhanced language list with better Android support -->
          <optgroup label="African Languages">
            <option value="am-ET">Amharic (አማርኛ)</option>
            <option value="ti-ET">Tigrinya (ትግርኛ)</option>
            <option value="om-ET">Oromo (Oromoo)</option>
            <option value="so-SO">Somali (Soomaali)</option>
            <option value="ha-NG">Hausa</option>
            <option value="sw-KE">Swahili</option>
          </optgroup>
          <optgroup label="European Languages">
            <option value="en-US" selected>English (US)</option>
            <option value="en-GB">English (UK)</option>
            <option value="es-ES">Spanish (Español)</option>
            <option value="fr-FR">French (Français)</option>
            <option value="de-DE">German (Deutsch)</option>
            <option value="it-IT">Italian (Italiano)</option>
            <option value="pt-BR">Portuguese (Português)</option>
            <option value="ru-RU">Russian (Русский)</option>
          </optgroup>
          <optgroup label="Asian Languages">
            <option value="ar-SA">Arabic (العربية)</option>
            <option value="fa-IR">Persian (فارسی)</option>
            <option value="hi-IN">Hindi (हिन्दी)</option>
            <option value="bn-IN">Bengali (বাংলা)</option>
            <option value="pa-IN">Punjabi (ਪੰਜਾਬੀ)</option>
            <option value="ja-JP">Japanese (日本語)</option>
            <option value="ko-KR">Korean (한국어)</option>
            <option value="zh-CN">Chinese (简体中文)</option>
            <option value="zh-TW">Chinese (繁體中文)</option>
          </optgroup>
          <optgroup label="Other Local Languages">
            <option value="zu-ZA">Zulu</option>
            <option value="xh-ZA">Xhosa</option>
            <option value="af-ZA">Afrikaans</option>
            <option value="ms-MY">Malay</option>
            <option value="id-ID">Indonesian</option>
            <option value="th-TH">Thai</option>
            <option value="vi-VN">Vietnamese</option>
          </optgroup>
        </select>

        <div class="confidence-indicator" id="confidenceIndicator">
          <div class="confidence-level" id="confidenceLevel"></div>
        </div>
      </div>

      <!-- Translation Panel -->
      <div class="translation-panel">
        <button id="translateBtn">Translate Text</button>
        <label for="targetLanguage">Target Language:</label>
        <select id="targetLanguage">
          <optgroup label="African Languages">
            <option value="am">Amharic</option>
            <option value="ti">Tigrinya</option>
            <option value="om">Oromo</option>
            <option value="so">Somali</option>
            <option value="ha">Hausa</option>
            <option value="sw">Swahili</option>
          </optgroup>
          <optgroup label="European Languages">
            <option value="en" selected>English</option>
            <option value="es">Spanish</option>
            <option value="fr">French</option>
            <option value="de">German</option>
            <option value="it">Italian</option>
            <option value="pt">Portuguese</option>
            <option value="ru">Russian</option>
          </optgroup>
          <optgroup label="Asian Languages">
            <option value="ar">Arabic</option>
            <option value="fa">Persian</option>
            <option value="hi">Hindi</option>
            <option value="bn">Bengali</option>
            <option value="pa">Punjabi</option>
            <option value="ja">Japanese</option>
            <option value="ko">Korean</option>
            <option value="zh">Chinese (Simplified)</option>
            <option value="zh-TW">Chinese (Traditional)</option>
          </optgroup>
        </select>
        <div class="translation-result" id="translationResult"></div>
      </div>

      <div class="audio-controls">
        <h3>Audio Settings</h3>
        <div class="audio-panel">
          <button id="startMicBtn">Start Microphone</button>
          <button id="stopMicBtn" disabled>Stop Microphone</button>
          <div style="flex: 1; min-width: 150px">
            <label for="volumeControl">Volume:</label>
            <input
              type="range"
              id="volumeControl"
              min="0"
              max="1"
              step="0.1"
              value="0.7"
              style="width: 100%"
            />
          </div>
        </div>
        <label for="audioInputSelect">Microphone Source:</label>
        <select id="audioInputSelect" style="width: 100%; margin-top: 8px">
          <option value="default">Default</option>
        </select>
        <div id="audioVisualizer"></div>
      </div>
    </div>
    <footer>
      Note: Speech recognition and translation require internet, but notes work
      offline.
    </footer>

    <div id="offlineIndicator" class="offline-status" style="display: none">
      OFFLINE MODE
    </div>

    <script>
      // Language direction mapping.
      const rtlLanguages = [
        "ar",
        "fa",
        "he",
        "ur",
        "ps",
        "ku",
        "sd",
        "dv",
        "yi",
        "ha",
      ];

      // Check online status and update UI.
      function updateOnlineStatus() {
        const offlineIndicator = document.getElementById("offlineIndicator");
        if (navigator.onLine) {
          offlineIndicator.style.display = "none";
        } else {
          offlineIndicator.style.display = "block";
        }
      }

      window.addEventListener("online", updateOnlineStatus);
      window.addEventListener("offline", updateOnlineStatus);
      updateOnlineStatus();

      // Initialize IndexedDB for offline storage.
      let db;
      const DB_NAME = "SpeechNotesDB";
      const DB_VERSION = 2; // Updated version for new features
      const STORE_NAME = "notes";

      function initDB() {
        return new Promise((resolve, reject) => {
          const request = indexedDB.open(DB_NAME, DB_VERSION);

          request.onerror = (event) => {
            console.error("Database error:", event.target.error);
            reject("Database error.");
          };

          request.onupgradeneeded = (event) => {
            const db = event.target.result;
            if (!db.objectStoreNames.contains(STORE_NAME)) {
              const store = db.createObjectStore(STORE_NAME, {
                keyPath: "id",
                autoIncrement: true,
              });
              // Create additional indexes for better querying
              store.createIndex("timestamp", "timestamp", { unique: false });
              store.createIndex("language", "language", { unique: false });
            }
          };

          request.onsuccess = (event) => {
            db = event.target.result;
            resolve(db);
          };
        });
      }

      // Save note to IndexedDB.
      async function saveNoteToDB(text, language) {
        if (!db) await initDB();

        return new Promise((resolve, reject) => {
          const transaction = db.transaction([STORE_NAME], "readwrite");
          const store = transaction.objectStore(STORE_NAME);

          const request = store.add({
            text: text,
            language: language,
            timestamp: new Date().toISOString(),
          });

          request.onsuccess = () => resolve(request.result);
          request.onerror = (event) => reject(event.target.error);
        });
      }

      // Get all notes from IndexedDB.
      async function getAllNotesFromDB() {
        if (!db) await initDB();

        return new Promise((resolve, reject) => {
          const transaction = db.transaction([STORE_NAME], "readonly");
          const store = transaction.objectStore(STORE_NAME);
          const request = store.getAll();

          request.onsuccess = () => resolve(request.result);
          request.onerror = (event) => reject(event.target.error);
        });
      }

      // Delete note from IndexedDB.
      async function deleteNoteFromDB(id) {
        if (!db) await initDB();

        return new Promise((resolve, reject) => {
          const transaction = db.transaction([STORE_NAME], "readwrite");
          const store = transaction.objectStore(STORE_NAME);
          const request = store.delete(id);

          request.onsuccess = () => resolve(true);
          request.onerror = (event) => reject(event.target.error);
        });
      }

      // Clear all notes from IndexedDB.
      async function clearAllNotesFromDB() {
        if (!db) await initDB();

        return new Promise((resolve, reject) => {
          const transaction = db.transaction([STORE_NAME], "readwrite");
          const store = transaction.objectStore(STORE_NAME);
          const request = store.clear();

          request.onsuccess = () => resolve(true);
          request.onerror = (event) => reject(event.target.error);
        });
      }

      // Function to export notes as Word document.
      async function exportAsDocx(notes) {
        try {
          // Load the docx library dynamically.
          const { default: docx } = await import(
            "https://cdn.jsdelivr.net/npm/docx@7.8.2/+esm"
          );

          // Create document structure.
          const { Document, Paragraph, TextRun, Packer } = docx;

          const doc = new Document({
            sections: [
              {
                properties: {},
                children: [
                  new Paragraph({
                    children: [
                      new TextRun({
                        text: "Speech to Text Notes Export",
                        bold: true,
                        size: 28,
                      }),
                    ],
                  }),
                  new Paragraph({
                    children: [
                      new TextRun({
                        text: `Exported on: ${new Date().toLocaleString()}`,
                        size: 22,
                        color: "666666",
                      }),
                    ],
                  }),
                  new Paragraph({ text: "" }), // Empty paragraph for spacing.

                  // Add all notes.
                  ...notes.flatMap((note) => [
                    new Paragraph({
                      children: [
                        new TextRun({
                          text: note.text,
                          size: 24,
                          rightToLeft: rtlLanguages.includes(
                            note.language?.split("-")[0]
                          ),
                        }),
                      ],
                    }),
                    new Paragraph({ text: "" }), // Spacing between notes.
                  ]),
                ],
              },
            ],
          });

          // Generate the Word document.
          const blob = await Packer.toBlob(doc);

          // Create download link.
          const url = URL.createObjectURL(blob);
          const a = document.createElement("a");
          a.href = url;
          a.download = "speech-notes-export.docx";
          document.body.appendChild(a);
          a.click();
          document.body.removeChild(a);
          URL.revokeObjectURL(url);
        } catch (error) {
          console.error("Error generating Word document:", error);
          alert("Failed to export as Word document.");
        }
      }

      // Function to export notes as TXT file.
      async function exportAsTxt(notes) {
        try {
          const textContent = notes.map((note) => note.text).join("\n\n");
          const blob = new Blob([textContent], { type: "text/plain" });
          const url = URL.createObjectURL(blob);
          const a = document.createElement("a");
          a.href = url;
          a.download = "speech-notes-export.txt";
          document.body.appendChild(a);
          a.click();
          document.body.removeChild(a);
          URL.revokeObjectURL(url);
        } catch (error) {
          console.error("Error generating TXT file:", error);
          alert("Failed to export as TXT file.");
        }
      }

      // Function to import Word documents.
      async function importDocxFile(file) {
        try {
          // Load the docx and mammoth libraries dynamically.
          const { default: mammoth } = await import(
            "https://cdn.jsdelivr.net/npm/mammoth@1.4.0/+esm"
          );

          const arrayBuffer = await new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onload = (event) => resolve(event.target.result);
            reader.onerror = reject;
            reader.readAsArrayBuffer(file);
          });

          const result = await mammoth.extractRawText({ arrayBuffer });
          const text = result.value;

          // Split text into notes (assuming each paragraph is a note).
          const notes = text
            .split("\n")
            .map((line) => line.trim())
            .filter((line) => line.length > 0)
            .map((line) => ({ text: line }));

          return notes;
        } catch (error) {
          console.error("Error reading Word document:", error);
          throw new Error("Could not read Word document.");
        }
      }

      // ========== ENHANCED TRANSLATION FUNCTION ==========
      async function translateText(text, targetLang) {
        // Check if text is valid
        if (!text || typeof text !== "string" || text.trim().length === 0) {
          console.error("Invalid text for translation");
          return "";
        }

        // Check if target language is valid
        const validLangs = Array.from(
          document.getElementById("targetLanguage").options
        )
          .map((opt) => opt.value)
          .filter((opt) => opt.value);

        if (!validLangs.includes(targetLang)) {
          console.error(`Invalid target language: ${targetLang}`);
          return text; // Return original text as fallback
        }

        try {
          // In a real implementation, you would:
          // 1. Use a proper translation API (Google, Azure, DeepL, etc.)
          // 2. Implement authentication
          // 3. Handle rate limiting
          // 4. Implement caching

          // Mock implementation - replace with actual API call
          console.log(
            `Translating to ${targetLang}: ${text.substring(0, 30)}...`
          );

          // Simulate network delay
          await new Promise((resolve) => setTimeout(resolve, 1000));

          // Mock translation - in reality this would be an API call
          if (targetLang === "es") {
            return `${text} (translated to Spanish)`;
          } else if (targetLang === "fr") {
            return `${text} (translated to French)`;
          }
          // Add more language cases as needed

          return `${text} (translated to ${targetLang})`;
        } catch (error) {
          console.error("Translation error:", error);
          // Fallback strategies:
          // 1. Return original text
          // 2. Try a cached translation
          // 3. Show error message
          return text;
        }
      }

      // Function to apply text direction based on language.
      function applyTextDirection(element, languageCode) {
        const baseLang = languageCode.split("-")[0];
        if (rtlLanguages.includes(baseLang)) {
          element.classList.add("rtl-text");
        } else {
          element.classList.remove("rtl-text");
        }
      }

      // Function to update confidence indicator
      function updateConfidenceIndicator(confidence) {
        const confidenceLevel = document.getElementById("confidenceLevel");
        if (confidenceLevel) {
          const percentage = Math.round(confidence * 100);
          confidenceLevel.style.width = `${percentage}%`;

          // Change color based on confidence level
          if (percentage > 80) {
            confidenceLevel.style.backgroundColor = "var(--success-color)";
          } else if (percentage > 50) {
            confidenceLevel.style.backgroundColor = "var(--warning-color)";
          } else {
            confidenceLevel.style.backgroundColor = "var(--danger-color)";
          }
        }
      }

      // Function to detect Android devices
      function isAndroid() {
        return /Android/i.test(navigator.userAgent);
      }

      // Function to detect Chrome browser
      function isChrome() {
        return /Chrome/i.test(navigator.userAgent);
      }

      // Function to check if a language is supported on the device
      async function checkLanguageSupport(languageCode) {
        if (!("webkitSpeechRecognition" in window)) {
          return false;
        }

        // Create a temporary recognition instance to check support
        const tempRecognition = new (window.SpeechRecognition ||
          window.webkitSpeechRecognition)();
        tempRecognition.lang = languageCode;

        return new Promise((resolve) => {
          tempRecognition.onerror = (event) => {
            resolve(event.error !== "language-not-supported");
          };

          tempRecognition.onstart = () => {
            tempRecognition.stop();
            resolve(true);
          };

          tempRecognition.start();
        });
      }

      // Audio processor worklet code as a string
      const audioProcessorWorkletCode = `
        class AudioProcessor extends AudioWorkletProcessor {
          process(inputs, outputs) {
            const input = inputs[0];
            const output = outputs[0];
            
            for (let channel = 0; channel < input.length; ++channel) {
              output[channel].set(input[channel]);
            }
            
            return true;
          }
        }
        
        registerProcessor('audio-processor', AudioProcessor);
      `;

      // Helper function to show alerts
      function showAlert(message, type = "info") {
        const colors = {
          info: "#3498db",
          warning: "#f39c12",
          error: "#e74c3c",
          success: "#2ecc71",
        };

        const alertDiv = document.createElement("div");
        alertDiv.style.position = "fixed";
        alertDiv.style.bottom = "20px";
        alertDiv.style.left = "50%";
        alertDiv.style.transform = "translateX(-50%)";
        alertDiv.style.backgroundColor = colors[type] || colors.info;
        alertDiv.style.color = "white";
        alertDiv.style.padding = "10px 20px";
        alertDiv.style.borderRadius = "5px";
        alertDiv.style.zIndex = "1000";
        alertDiv.style.boxShadow = "0 2px 10px rgba(0,0,0,0.2)";
        alertDiv.textContent = message;

        document.body.appendChild(alertDiv);

        setTimeout(() => {
          alertDiv.style.opacity = "0";
          setTimeout(() => document.body.removeChild(alertDiv), 300);
        }, 3000);
      }

      document.addEventListener("DOMContentLoaded", async function () {
        const textDisplay = document.getElementById("textDisplay");
        const notesList = document.getElementById("notesList");
        const toggleBtn = document.getElementById("toggleBtn");
        const addNoteBtn = document.getElementById("addNoteBtn");
        const clearBtn = document.getElementById("clearBtn");
        const exportBtn = document.getElementById("exportBtn");
        const importBtn = document.getElementById("importBtn");
        const status = document.getElementById("status");
        const languageSelect = document.getElementById("languageSelect");
        const translateBtn = document.getElementById("translateBtn");
        const targetLanguage = document.getElementById("targetLanguage");
        const translationResult = document.getElementById("translationResult");
        const startMicBtn = document.getElementById("startMicBtn");
        const stopMicBtn = document.getElementById("stopMicBtn");
        const volumeControl = document.getElementById("volumeControl");
        const audioVisualizer = document.getElementById("audioVisualizer");
        const androidWarning = document.getElementById("androidWarning");
        const audioInputSelect = document.getElementById("audioInputSelect");

        // Show Android-specific instructions
        if (isAndroid()) {
          androidWarning.style.display = "block";
          if (!isChrome()) {
            androidWarning.innerHTML +=
              "<br><br><strong>Recommendation:</strong> For best local language support, please use Google Chrome browser.";
          }
        } else {
          androidWarning.style.display = "none";
        }

        // Initialize database.
        try {
          await initDB();
          // Load existing notes.
          const notes = await getAllNotesFromDB();
          notes.forEach((note) => {
            addNoteToUI(note.text, note.id, note.language);
          });
        } catch (error) {
          console.error("Failed to initialize database:", error);
        }

        let recognition;
        let isListening = false;
        let isAutoListening = true;
        let finalTranscript = "";
        let audioContext;
        let microphone;
        let analyser;
        let gainNode;
        let isMicActive = false;
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob;
        let audioUrl;
        let touchStartX = 0;
        let touchEndX = 0;
        let lastConfidence = 0;

        // Check for browser support.
        if (
          !("webkitSpeechRecognition" in window) &&
          !("SpeechRecognition" in window)
        ) {
          status.innerHTML =
            '<span style="color:red;">Speech recognition not supported in your browser. Try Chrome or Edge.</span>';
          toggleBtn.disabled = true;
          addNoteBtn.disabled = true;
          return;
        }

        // Initialize recognition with audio context support
        function initRecognition() {
          const SpeechRecognition =
            window.SpeechRecognition || window.webkitSpeechRecognition;
          recognition = new SpeechRecognition();

          recognition.continuous = true;
          recognition.interimResults = true;
          recognition.maxAlternatives = 1; // Changed from 3 to 1 to reduce duplicates

          // Add audio context to help with headset issues
          if (audioContext) {
            recognition.audioContext = audioContext;
          }

          // Set up recognition event handlers
          recognition.onresult = function (event) {
            let interimTranscript = "";
            let newFinalTranscript = "";
            let isAndroidDevice = isAndroid();

            // Process all new results since last result
            for (let i = event.resultIndex; i < event.results.length; i++) {
              const result = event.results[i];
              
              // For Android, only use final results to avoid duplicates
              if (isAndroidDevice && !result.isFinal) {
                continue;
              }

              const transcript = result[0].transcript;
              const confidence = result[0].confidence || 0;

              if (result.isFinal) {
                // For Android, check if this is a duplicate of the last final result
                if (!isAndroidDevice || 
                    !finalTranscript.endsWith(transcript.trim() + " ")) {
                  newFinalTranscript += transcript + " ";
                }
              } else {
                interimTranscript = transcript;
              }

              // Update confidence indicator
              if (confidence > lastConfidence) {
                lastConfidence = confidence;
                updateConfidenceIndicator(confidence);
              }
            }

            // Only update final transcript if we have new final results
            if (newFinalTranscript) {
              finalTranscript += newFinalTranscript;
            }

            // Update the display with both final and interim results
            updateTextDisplay(finalTranscript, interimTranscript);
          };

          recognition.onend = function () {
            if (isAutoListening) {
              setTimeout(() => {
                try {
                  recognition.start();
                } catch (e) {
                  console.log("Auto-restart failed, retrying...", e);
                  setTimeout(() => {
                    if (isAutoListening) recognition.start();
                  }, 200); // Slightly longer delay on retry
                }
              }, 50); // Very short delay for restart
            }
          };

          recognition.onstart = function () {
            isListening = true;
            status.innerHTML =
              '<span class="listening-indicator"></span>Listening... Speak now!';
            status.style.backgroundColor = "#e8f5e9";
            toggleBtn.textContent = "Pause Listening";

            // Reset confidence indicator
            updateConfidenceIndicator(0);
          };

          recognition.onerror = function (event) {
            console.error("Recognition error:", event.error);
            isListening = false;

            let errorMessage = "Error occurred.";
            switch (event.error) {
              case "no-speech":
                errorMessage = "No speech detected.";
                break;
              case "audio-capture":
                errorMessage = "Microphone not available.";
                break;
              case "not-allowed":
                errorMessage = "Microphone access denied.";
                break;
              case "service-not-allowed":
                errorMessage = "Speech recognition service not allowed.";
                break;
              case "network":
                errorMessage = "Network error occurred.";
                break;
              case "language-not-supported":
                errorMessage =
                  "Selected language not supported on this device.";
                // Try to switch to a supported language
                if (isAndroid()) {
                  const fallbackLang = "en-US";
                  languageSelect.value = fallbackLang;
                  recognition.lang = fallbackLang;
                  errorMessage += ` Switched to ${fallbackLang} as fallback.`;
                }
                break;
              default:
                errorMessage = `Error: ${event.error}`;
            }

            status.innerHTML = `<span style="color:red;">${errorMessage}</span>`;
            status.style.backgroundColor = "#ffebee";
            toggleBtn.textContent = "Start Listening";

            // Reset confidence indicator on error
            updateConfidenceIndicator(0);

            // Different delay strategies based on error type
            let retryDelay = 500; // Default delay

            if (event.error === "no-speech") {
              retryDelay = 1000; // Longer delay for no speech
            } else if (event.error === "network") {
              retryDelay = 2000; // Even longer for network issues
            } else if (event.error === "language-not-supported") {
              retryDelay = 1500; // Medium delay for language issues
            }

            setTimeout(() => {
              if (isAutoListening) recognition.start();
            }, retryDelay);
          };
        }

        // Efficient UI update function.
        function updateTextDisplay(final, interim) {
          // Use requestAnimationFrame for smoother UI updates.
          requestAnimationFrame(() => {
            textDisplay.innerHTML =
              final +
              (interim
                ? '<span style="color:#aaa;">' + interim + "</span>"
                : "");
          });
        }

        // Set initial language based on device
        async function setInitialLanguage() {
          const userLang = navigator.language || "en-US";
          const availableLangs = Array.from(languageSelect.options).map(
            (opt) => opt.value
          );

          // Check which languages are actually supported
          const supportedLangs = [];
          for (const lang of availableLangs) {
            const isSupported = await checkLanguageSupport(lang);
            if (isSupported) {
              supportedLangs.push(lang);
            }
          }

          // Try to set the best matching language
          let selectedLang = "en-US"; // Default fallback

          if (supportedLangs.includes(userLang)) {
            selectedLang = userLang;
          } else {
            // Try to find a matching base language
            const baseLang = userLang.split("-")[0];
            const matchingLang = supportedLangs.find((lang) =>
              lang.startsWith(baseLang)
            );
            if (matchingLang) {
              selectedLang = matchingLang;
            } else if (supportedLangs.length > 0) {
              // Fallback to first supported language
              selectedLang = supportedLangs[0];
            }
          }

          languageSelect.value = selectedLang;
          if (recognition) {
            recognition.lang = selectedLang;
          }
          applyTextDirection(textDisplay, selectedLang);

          // Update the language dropdown to show supported languages
          Array.from(languageSelect.options).forEach((option) => {
            option.disabled = !supportedLangs.includes(option.value);
          });
        }

        // Initialize recognition
        initRecognition();
        await setInitialLanguage();

        // Start listening with faster initialization.
        if (navigator.onLine) {
          setTimeout(() => {
            try {
              recognition.start();
            } catch (e) {
              console.log("Initial start failed, retrying...", e);
              setTimeout(() => {
                try {
                  recognition.start();
                } catch (e2) {
                  console.log("Second attempt failed:", e2);
                  status.innerHTML =
                    '<span style="color:red;">Microphone error. Refresh and allow access.</span>';
                }
              }, 300); // Faster retry.
            }
          }, 100); // Shorter initial delay.
        }

        // Populate audio input devices dropdown
        async function updateAudioInputs() {
          try {
            const devices = await navigator.mediaDevices.enumerateDevices();
            const audioInputs = devices.filter(
              (device) => device.kind === "audioinput"
            );

            // Clear existing options except default
            while (audioInputSelect.options.length > 1) {
              audioInputSelect.remove(1);
            }

            // Add new options
            audioInputs.forEach((device) => {
              const option = document.createElement("option");
              option.value = device.deviceId;
              option.text =
                device.label || `Microphone ${audioInputSelect.options.length}`;
              audioInputSelect.appendChild(option);
            });
          } catch (err) {
            console.error("Error enumerating devices:", err);
          }
        }

        // Call initially and whenever devices might change
        updateAudioInputs();
        navigator.mediaDevices.addEventListener(
          "devicechange",
          updateAudioInputs
        );

        // Initialize audio context.
        function initAudioContext() {
          try {
            audioContext = new (window.AudioContext ||
              window.webkitAudioContext)();
            console.log("Audio context created.");
            return true;
          } catch (e) {
            console.error("Web Audio API not supported.", e);
            status.innerHTML =
              '<span style="color:red;">Web Audio API not supported in your browser.</span>';
            return false;
          }
        }

        // Start microphone with proper error handling.
        startMicBtn.addEventListener("click", async function () {
          try {
            // First stop any existing microphone
            if (isMicActive) {
              if (mediaRecorder && mediaRecorder.state !== "inactive") {
                mediaRecorder.stop();
              }
              if (microphone) microphone.disconnect();
            }

            // Initialize audio context if needed
            if (!audioContext && !initAudioContext()) {
              return;
            }

            // Get selected device ID
            const deviceId =
              audioInputSelect.value === "default"
                ? undefined
                : audioInputSelect.value;

            // Get user media with better device handling
            const stream = await navigator.mediaDevices.getUserMedia({
              audio: {
                deviceId: deviceId,
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true,
                channelCount: 1, // Mono often works better
              },
              video: false,
            });

            // Create nodes.
            gainNode = audioContext.createGain();
            gainNode.gain.value = volumeControl.value;

            analyser = audioContext.createAnalyser();
            analyser.fftSize = 256;

            // Create source and connect nodes.
            microphone = audioContext.createMediaStreamSource(stream);

            // Add audio processing for better headset compatibility
            if (audioContext.createAudioWorklet) {
              try {
                // Create a blob URL for the audio processor worklet
                const blob = new Blob([audioProcessorWorkletCode], {
                  type: "application/javascript",
                });
                const url = URL.createObjectURL(blob);

                await audioContext.audioWorklet.addModule(url);
                const workletNode = new AudioWorkletNode(
                  audioContext,
                  "audio-processor"
                );
                microphone.connect(workletNode);
                workletNode.connect(analyser);
              } catch (e) {
                console.warn(
                  "AudioWorklet not available, using script processor"
                );
                const scriptNode = audioContext.createScriptProcessor(
                  4096,
                  1,
                  1
                );
                microphone.connect(scriptNode);
                scriptNode.connect(analyser);
              }
            } else {
              microphone.connect(gainNode);
              gainNode.connect(analyser);
            }

            analyser.connect(audioContext.destination);

            // Setup visualization.
            setupVisualizer();

            // Setup recording.
            mediaRecorder = new MediaRecorder(stream);
            audioChunks = [];

            mediaRecorder.ondataavailable = function (e) {
              if (e.data.size > 0) {
                audioChunks.push(e.data);
              }
            };

            mediaRecorder.onstop = function () {
              audioBlob = new Blob(audioChunks, { type: "audio/wav" });
              audioUrl = URL.createObjectURL(audioBlob);
            };

            mediaRecorder.start(100); // Collect 100ms chunks.
            isMicActive = true;

            // Update UI.
            startMicBtn.disabled = true;
            stopMicBtn.disabled = false;
            status.innerHTML =
              '<span class="listening-indicator"></span>Microphone active - recording audio.';
          } catch (error) {
            console.error("Microphone error:", error);
            status.innerHTML = `<span style="color:red;">Microphone error: ${error.message}</span>`;
          }
        });

        // Stop microphone properly.
        stopMicBtn.addEventListener("click", function () {
          if (!isMicActive) return;

          try {
            if (mediaRecorder && mediaRecorder.state !== "inactive") {
              mediaRecorder.stop();
            }

            // Disconnect all nodes.
            if (microphone) microphone.disconnect();
            if (gainNode) gainNode.disconnect();
            if (analyser) analyser.disconnect();

            isMicActive = false;
            startMicBtn.disabled = false;
            stopMicBtn.disabled = true;
            status.innerHTML = "Microphone stopped.";
          } catch (err) {
            console.error("Error stopping microphone:", err);
          }
        });

        // Volume control.
        volumeControl.addEventListener("input", function () {
          if (gainNode) {
            gainNode.gain.value = this.value;
          }
        });

        // Visualizer with proper animation frame handling.
        function setupVisualizer() {
          const canvas = document.createElement("canvas");
          canvas.width = audioVisualizer.offsetWidth;
          canvas.height = audioVisualizer.offsetHeight;
          audioVisualizer.innerHTML = "";
          audioVisualizer.appendChild(canvas);

          const canvasCtx = canvas.getContext("2d");
          const bufferLength = analyser.frequencyBinCount;
          const dataArray = new Uint8Array(bufferLength);
          let animationId;

          function draw() {
            if (!isMicActive) {
              cancelAnimationFrame(animationId);
              return;
            }

            animationId = requestAnimationFrame(draw);
            analyser.getByteFrequencyData(dataArray);

            canvasCtx.fillStyle = "rgb(200, 200, 200)";
            canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

            const barWidth = (canvas.width / bufferLength) * 2.5;
            let x = 0;

            for (let i = 0; i < bufferLength; i++) {
              const barHeight = dataArray[i] / 2;
              const hue = (i / bufferLength) * 360;

              canvasCtx.fillStyle = `hsl(${hue}, 100%, 50%)`;
              canvasCtx.fillRect(
                x,
                canvas.height - barHeight,
                barWidth,
                barHeight
              );

              x += barWidth + 1;
            }
          }

          draw();
        }

        // Handle window resize.
        window.addEventListener("resize", function () {
          if (isMicActive) {
            setupVisualizer();
          }
        });

        // Button event listeners.
        toggleBtn.addEventListener("click", function () {
          this.disabled = true;

          if (isListening) {
            // Pause listening.
            isAutoListening = false;
            try {
              recognition.stop();
            } catch (e) {
              console.log("Error stopping recognition:", e);
            }
            isListening = false;
            toggleBtn.textContent = "Start Listening";
            status.textContent = "Listening paused.";
            status.style.backgroundColor = "#fff3e0";
          } else {
            // Start listening.
            isAutoListening = true;
            recognition.lang = languageSelect.value;
            try {
              recognition.start();
            } catch (e) {
              console.log("Error starting recognition:", e);
              status.innerHTML =
                '<span style="color:red;">Error starting microphone. Please refresh and allow permissions.</span>';
              setTimeout(() => {
                if (isAutoListening) recognition.start();
              }, 300); // Faster retry.
            }
          }

          setTimeout(() => {
            this.disabled = false;
          }, 300); // Faster re-enable.
        });

        addNoteBtn.addEventListener("click", async function () {
          if (
            textDisplay.textContent.trim() &&
            textDisplay.textContent.trim() !==
              "Your transcribed text will appear here..."
          ) {
            const noteText = textDisplay.textContent.trim();
            const currentLanguage = languageSelect.value;
            try {
              const noteId = await saveNoteToDB(noteText, currentLanguage);
              addNoteToUI(noteText, noteId, currentLanguage);
              // Only clear the text display, not the finalTranscript
              textDisplay.textContent = "";
            } catch (error) {
              console.error("Failed to save note:", error);
              // Fallback to localStorage if IndexedDB fails.
              addNoteToUI(noteText, null, currentLanguage);
              textDisplay.textContent = "";
            }
          }
        });

        clearBtn.addEventListener("click", async function () {
          if (confirm("Are you sure you want to clear all notes?")) {
            textDisplay.textContent = "";
            notesList.innerHTML = "";
            finalTranscript = "";
            try {
              await clearAllNotesFromDB();
            } catch (error) {
              console.error("Failed to clear notes:", error);
            }
          }
        });

        // Updated export button with dialog
        exportBtn.addEventListener("click", async function () {
          try {
            const notes = await getAllNotesFromDB();
            if (notes.length === 0) {
              alert("No notes to export.");
              return;
            }

            // Create export dialog
            const exportDialog = document.createElement("div");
            exportDialog.className = "export-dialog";
            exportDialog.innerHTML = `
                    <h3>Export Options</h3>
                    <button id="exportDocx">Export as Word Document (.docx)</button>
                    <button id="exportTxt">Export as Text File (.txt)</button>
                    <button id="exportCancel">Cancel</button>
                `;

            document.body.appendChild(exportDialog);

            // Add event listeners to dialog buttons
            document
              .getElementById("exportDocx")
              .addEventListener("click", async function () {
                await exportAsDocx(notes);
                document.body.removeChild(exportDialog);
              });

            document
              .getElementById("exportTxt")
              .addEventListener("click", async function () {
                await exportAsTxt(notes);
                document.body.removeChild(exportDialog);
              });

            document
              .getElementById("exportCancel")
              .addEventListener("click", function () {
                document.body.removeChild(exportDialog);
              });
          } catch (error) {
            console.error("Export failed:", error);
            alert("Failed to export notes.");
          }
        });

        importBtn.addEventListener("click", function () {
          const fileInput = document.createElement("input");
          fileInput.type = "file";
          fileInput.accept = ".docx,.txt";

          fileInput.addEventListener("change", async function (e) {
            const file = e.target.files[0];
            if (!file) return;

            const reader = new FileReader();
            reader.onload = async function (e) {
              try {
                let notes = [];

                if (file.name.endsWith(".docx")) {
                  // Handle Word document import.
                  notes = await importDocxFile(file);
                } else if (file.name.endsWith(".txt")) {
                  // Handle plain text import.
                  const text = e.target.result;
                  notes = text
                    .split("\n")
                    .map((line) => line.trim())
                    .filter((line) => line.length > 0)
                    .map((line) => ({ text: line }));
                }

                // Clear existing notes.
                notesList.innerHTML = "";
                await clearAllNotesFromDB();

                // Add new notes.
                for (const note of notes) {
                  try {
                    const text = typeof note === "string" ? note : note.text;
                    const language = note.language || languageSelect.value;
                    const noteId = await saveNoteToDB(text, language);
                    addNoteToUI(text, noteId, language);
                  } catch (error) {
                    console.error("Failed to import note:", error);
                    const text = typeof note === "string" ? note : note.text;
                    addNoteToUI(text, null, languageSelect.value);
                  }
                }

                alert(`Successfully imported ${notes.length} notes.`);
              } catch (error) {
                console.error("Import failed:", error);
                alert("Failed to import notes. Invalid file format.");
              }
            };

            if (file.name.endsWith(".docx")) {
              // Read as array buffer for Word documents.
              reader.readAsArrayBuffer(file);
            } else {
              // Read as text for TXT files.
              reader.readAsText(file);
            }
          });

          fileInput.click();
        });

        // Translation button event listener with enhanced error handling
        translateBtn.addEventListener("click", async function () {
          if (
            !textDisplay.textContent.trim() ||
            textDisplay.textContent.trim() ===
              "Your transcribed text will appear here..."
          ) {
            showAlert("No text to translate.", "warning");
            return;
          }

          if (!navigator.onLine) {
            showAlert("Translation requires internet connection.", "warning");
            return;
          }

          try {
            translateBtn.disabled = true;
            translateBtn.textContent = "Translating...";
            translationResult.textContent = "Processing...";

            const textToTranslate = textDisplay.textContent.trim();
            const targetLang = targetLanguage.value;

            // Use the enhanced translation function
            const translation = await translateText(
              textToTranslate,
              targetLang
            );

            translationResult.textContent = translation;
            applyTextDirection(translationResult, targetLang);
          } catch (error) {
            console.error("Translation failed:", error);
            showAlert("Translation failed. Please try again.", "error");
            translationResult.textContent = "Translation error";
          } finally {
            translateBtn.disabled = false;
            translateBtn.textContent = "Translate Text";
          }
        });

        languageSelect.addEventListener("change", function () {
          if (recognition) {
            recognition.lang = this.value;
            applyTextDirection(textDisplay, this.value);
            if (isListening) {
              recognition.stop();
              setTimeout(() => recognition.start(), 100); // Faster restart.
            }
          }
        });

        function addNoteToUI(text, id, language) {
          const noteItem = document.createElement("li");
          noteItem.className = "note-item";
          noteItem.dataset.id = id || Date.now();

          const noteText = document.createElement("span");
          noteText.textContent = text;

          // Apply text direction based on language.
          if (language) {
            const baseLang = language.split("-")[0];
            if (rtlLanguages.includes(baseLang)) {
              noteItem.classList.add("rtl-text");
            }
          }

          const deleteBtn = document.createElement("button");
          deleteBtn.className = "delete-note";
          deleteBtn.innerHTML = "×";
          deleteBtn.addEventListener("click", async function () {
            noteItem.remove();
            if (id) {
              try {
                await deleteNoteFromDB(id);
              } catch (error) {
                console.error("Failed to delete note from DB:", error);
              }
            }
          });

          // Add touch events for mobile with swipe to delete.
          noteItem.addEventListener(
            "touchstart",
            function (e) {
              touchStartX = e.changedTouches[0].screenX;
              noteItem.classList.add("swiping");
            },
            { passive: true }
          );

          noteItem.addEventListener(
            "touchmove",
            function (e) {
              touchEndX = e.changedTouches[0].screenX;
              const diff = touchStartX - touchEndX;
              if (diff > 30) {
                // Swipe left.
                noteItem.style.transform = `translateX(${-diff}px)`;
                if (diff > 100) {
                  deleteBtn.style.opacity = "1";
                }
              }
            },
            { passive: true }
          );

          noteItem.addEventListener(
            "touchend",
            function () {
              noteItem.classList.remove("swiping");
              const diff = touchStartX - touchEndX;
              if (diff > 100) {
                // Trigger delete.
                deleteBtn.click();
              } else {
                noteItem.style.transform = "";
              }
            },
            { passive: true }
          );

          noteItem.appendChild(noteText);
          noteItem.appendChild(deleteBtn);
          notesList.appendChild(noteItem);

          noteItem.scrollIntoView({ behavior: "smooth" });
        }

        textDisplay.addEventListener("keydown", function (e) {
          if (e.key === "Enter") {
            e.preventDefault();
            addNoteBtn.click();
          }
        });

        // Page visibility handling.
        document.addEventListener("visibilitychange", function () {
          if (document.visibilityState === "hidden" && isListening) {
            recognition.stop();
          } else if (
            document.visibilityState === "visible" &&
            isAutoListening
          ) {
            setTimeout(() => recognition.start(), 100); // Faster restart.
          }
        });

        // Beforeunload handling.
        window.addEventListener("beforeunload", function (e) {
          if (isListening) {
            recognition.stop();
          }
        });
      });

      // Service worker registration.
      if ("serviceWorker" in navigator) {
        window.addEventListener("load", () => {
          navigator.serviceWorker
            .register("sw.js")
            .then((registration) => {
              console.log("ServiceWorker registration successful.");
            })
            .catch((err) => {
              console.log("ServiceWorker registration failed: ", err);
            });
        });
      }

      // Install prompt handling.
      let deferredPrompt;
      window.addEventListener("beforeinstallprompt", (e) => {
        e.preventDefault();
        deferredPrompt = e;

        const installBtn = document.createElement("button");
        installBtn.textContent = "Install App";
        installBtn.style.position = "fixed";
        installBtn.style.bottom = "20px";
        installBtn.style.right = "20px";
        installBtn.style.zIndex = "1000";
        installBtn.style.padding = "10px 15px";
        installBtn.style.backgroundColor = "#4CAF50";
        installBtn.style.color = "white";
        installBtn.style.border = "none";
        installBtn.style.borderRadius = "5px";
        installBtn.style.boxShadow = "0 2px 5px rgba(0,0,0,0.2)";

        installBtn.addEventListener("click", () => {
          deferredPrompt.prompt();
          deferredPrompt.userChoice.then((choiceResult) => {
            if (choiceResult.outcome === "accepted") {
              console.log("User accepted install.");
            }
            deferredPrompt = null;
          });
        });

        document.body.appendChild(installBtn);

        setTimeout(() => {
          installBtn.style.display = "none";
        }, 10000);
      });
    </script>
  </body>
</html>
